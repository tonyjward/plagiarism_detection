{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Plagiarism\n",
    "In this notebook we'll use our trained PyTorch model to investigate plagiarism in Medium articles. The hyperlinks don't display nicely on github so they can be accessed at here instead\n",
    "\n",
    "Prior to runnig this notebook it is necessary to run the following from the root directory\n",
    "\n",
    "### Launch Selenium Webbrowser\n",
    "\n",
    "`sudo docker run -d --rm --name standalone-firefox -p 4444:4444 -p 5900:5900 --shm-size 2g selenium/standalone-firefox-debug:3.141.59`\n",
    "\n",
    "### Scrape Medium\n",
    "`./scrape_data.sh '[logistic regression,naive bayes]' data`\n",
    "\n",
    "### Perform Feature Engineering\n",
    "`./check_plagiarism.sh '[logistic regression,naive bayes]' data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../') \n",
    "\n",
    "MODEL_DIR = '../model'\n",
    "DATA_DIR = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "Here we load our PyTorch model which we trained in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.model import BinaryClassifier, predict\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load the PyTorch model from the `model_dir` directory.\"\"\"\n",
    "    print(\"Loading model.\")\n",
    "\n",
    "    # First, load the parameters used to create the model.\n",
    "    model_info = {}\n",
    "    model_info_path = os.path.join(model_dir, 'model_info.pth')\n",
    "    with open(model_info_path, 'rb') as f:\n",
    "        model_info = torch.load(f)\n",
    "\n",
    "    print(\"model_info: {}\".format(model_info))\n",
    "\n",
    "    # Determine the device and construct the model.\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = BinaryClassifier(model_info['input_features'], model_info['hidden_dim'], model_info['output_dim'])\n",
    "\n",
    "    # Load the stored model parameters.\n",
    "    model_path = os.path.join(model_dir, 'model.pth')\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "\n",
    "    # set to eval mode, could use no_grad\n",
    "    model.to(device).eval()\n",
    "\n",
    "    print(\"Done loading model.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model.\n",
      "model_info: {'input_features': 2, 'hidden_dim': 7, 'output_dim': 1}\n",
      "Done loading model.\n"
     ]
    }
   ],
   "source": [
    "model = model_fn(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "Here we define two helper functions that we'll use to predict curtailment probability and display the hyperlinks of the top 5 most likely article pairs to contain plagiarism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def predict_curtailment(search_term, min_length = 300):\n",
    "    '''\n",
    "    Load the feature matrix for the provided search term and exclude results for \n",
    "    articles with fewer than the min_length number of words\n",
    "    '''\n",
    "    \n",
    "    # load features\n",
    "    feature_matrix = pickle.load(open(os.path.join(DATA_DIR, f\"{search_term}_feature_matrix.p\"), 'rb'))\n",
    "    \n",
    "    # remove short articles\n",
    "    feature_matrix = feature_matrix[(feature_matrix['word_count_A']>min_length) & (feature_matrix['word_count_B'] > min_length)]\n",
    "    \n",
    "    # sort data by predicted curtailment probability\n",
    "    feature_matrix['curtailment_prob'] = predict(feature_matrix[['c_20', 'lcs_word']].values, model)\n",
    "    feature_matrix.sort_values('curtailment_prob', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_links(feature_matrix, top_n=5):\n",
    "    '''\n",
    "    Display the hyperlinks for the top n most likely article pairs to contain plagiarism'''\n",
    "    for idx in range(top_n):\n",
    "        print(f\"Potential plagiarism: {idx}\")\n",
    "        print(feature_matrix.loc[idx, 'link_A'])\n",
    "        print(feature_matrix.loc[idx, 'link_B'])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting class probabilities for the input data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>author_A</th>\n",
       "      <th>author_B</th>\n",
       "      <th>link_A</th>\n",
       "      <th>link_B</th>\n",
       "      <th>article_A</th>\n",
       "      <th>article_B</th>\n",
       "      <th>c_20</th>\n",
       "      <th>lcs_word</th>\n",
       "      <th>word_count_A</th>\n",
       "      <th>word_count_B</th>\n",
       "      <th>curtailment_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>Jingles (Hong Jing)</td>\n",
       "      <td>Elenjubbas</td>\n",
       "      <td>https://towardsdatascience.com/why-linear-regr...</td>\n",
       "      <td>https://medium.com/@elenjubbas/linear-regressi...</td>\n",
       "      <td>Why Linear Regression is not suitable for Clas...</td>\n",
       "      <td>Linear Regression vs. Logistic Regression for ...</td>\n",
       "      <td>0.441468</td>\n",
       "      <td>0.510222</td>\n",
       "      <td>1125</td>\n",
       "      <td>600</td>\n",
       "      <td>0.850483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>299</td>\n",
       "      <td>ROHITH RAMESH</td>\n",
       "      <td>Sarang Narkhede</td>\n",
       "      <td>https://medium.com/analytics-vidhya/logistic-r...</td>\n",
       "      <td>https://towardsdatascience.com/understanding-l...</td>\n",
       "      <td>Logistic Regression - Analytics Vidhya - Mediu...</td>\n",
       "      <td>Understanding Logistic Regression - Towards Da...</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.442217</td>\n",
       "      <td>848</td>\n",
       "      <td>654</td>\n",
       "      <td>0.775918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>187</td>\n",
       "      <td>Rajwrita Nath</td>\n",
       "      <td>Apoorva Agrawal</td>\n",
       "      <td>https://medium.com/@rajwritanath/logistic-regr...</td>\n",
       "      <td>https://medium.com/data-science-group-iitr/log...</td>\n",
       "      <td>Logistic Regression- the Theory and Code - Raj...</td>\n",
       "      <td>Logistic Regression. Simplified. - Data Scienc...</td>\n",
       "      <td>0.240994</td>\n",
       "      <td>0.395657</td>\n",
       "      <td>829</td>\n",
       "      <td>845</td>\n",
       "      <td>0.756825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>189</td>\n",
       "      <td>Harshit Nigam</td>\n",
       "      <td>Animesh Agarwal</td>\n",
       "      <td>https://medium.com/essence-of-learning/learnin...</td>\n",
       "      <td>https://towardsdatascience.com/building-a-logi...</td>\n",
       "      <td>Learning Logistic Regression - Essence of Lear...</td>\n",
       "      <td>Building a Logistic Regression in Python - Tow...</td>\n",
       "      <td>0.092420</td>\n",
       "      <td>0.339979</td>\n",
       "      <td>953</td>\n",
       "      <td>1445</td>\n",
       "      <td>0.627052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>252</td>\n",
       "      <td>David Fumo</td>\n",
       "      <td>Hiromi Suenaga</td>\n",
       "      <td>https://medium.com/simple-ai/logistic-regressi...</td>\n",
       "      <td>https://medium.com/@hiromi_suenaga/machine-lea...</td>\n",
       "      <td>Logistic Regression — Intro To Machine Learnin...</td>\n",
       "      <td>Machine Learning 1: Lesson 10 - Hiromi Suenaga...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423221</td>\n",
       "      <td>534</td>\n",
       "      <td>12775</td>\n",
       "      <td>0.604702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B             author_A         author_B  \\\n",
       "0  107  108  Jingles (Hong Jing)       Elenjubbas   \n",
       "1   78  299        ROHITH RAMESH  Sarang Narkhede   \n",
       "2  152  187        Rajwrita Nath  Apoorva Agrawal   \n",
       "3  182  189        Harshit Nigam  Animesh Agarwal   \n",
       "4   89  252           David Fumo   Hiromi Suenaga   \n",
       "\n",
       "                                              link_A  \\\n",
       "0  https://towardsdatascience.com/why-linear-regr...   \n",
       "1  https://medium.com/analytics-vidhya/logistic-r...   \n",
       "2  https://medium.com/@rajwritanath/logistic-regr...   \n",
       "3  https://medium.com/essence-of-learning/learnin...   \n",
       "4  https://medium.com/simple-ai/logistic-regressi...   \n",
       "\n",
       "                                              link_B  \\\n",
       "0  https://medium.com/@elenjubbas/linear-regressi...   \n",
       "1  https://towardsdatascience.com/understanding-l...   \n",
       "2  https://medium.com/data-science-group-iitr/log...   \n",
       "3  https://towardsdatascience.com/building-a-logi...   \n",
       "4  https://medium.com/@hiromi_suenaga/machine-lea...   \n",
       "\n",
       "                                           article_A  \\\n",
       "0  Why Linear Regression is not suitable for Clas...   \n",
       "1  Logistic Regression - Analytics Vidhya - Mediu...   \n",
       "2  Logistic Regression- the Theory and Code - Raj...   \n",
       "3  Learning Logistic Regression - Essence of Lear...   \n",
       "4  Logistic Regression — Intro To Machine Learnin...   \n",
       "\n",
       "                                           article_B      c_20  lcs_word  \\\n",
       "0  Linear Regression vs. Logistic Regression for ...  0.441468  0.510222   \n",
       "1  Understanding Logistic Regression - Towards Da...  0.242424  0.442217   \n",
       "2  Logistic Regression. Simplified. - Data Scienc...  0.240994  0.395657   \n",
       "3  Building a Logistic Regression in Python - Tow...  0.092420  0.339979   \n",
       "4  Machine Learning 1: Lesson 10 - Hiromi Suenaga...  0.000000  0.423221   \n",
       "\n",
       "   word_count_A  word_count_B  curtailment_prob  \n",
       "0          1125           600          0.850483  \n",
       "1           848           654          0.775918  \n",
       "2           829           845          0.756825  \n",
       "3           953          1445          0.627052  \n",
       "4           534         12775          0.604702  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = predict_curtailment('logistic_regression')\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential plagiarism: 0\n",
      "https://towardsdatascience.com/why-linear-regression-is-not-suitable-for-binary-classification-c64457be8e28?source=search_post\n",
      "https://medium.com/@elenjubbas/linear-regression-vs-logistic-regression-for-classification-tasks-b42f85487857?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 1\n",
      "https://medium.com/analytics-vidhya/logistic-regression-f9845e1aca5e?source=search_post\n",
      "https://towardsdatascience.com/understanding-logistic-regression-9b02c2aec102?source=search_post---------8\n",
      "\n",
      "\n",
      "Potential plagiarism: 2\n",
      "https://medium.com/@rajwritanath/logistic-regression-the-the-e8ed646e6a29?source=search_post\n",
      "https://medium.com/data-science-group-iitr/logistic-regression-simplified-9b4efe801389?source=search_post---------6\n",
      "\n",
      "\n",
      "Potential plagiarism: 3\n",
      "https://medium.com/essence-of-learning/learning-logistic-regression-17d35a985813?source=search_post\n",
      "https://towardsdatascience.com/building-a-logistic-regression-in-python-301d27367c24?source=search_post---------7\n",
      "\n",
      "\n",
      "Potential plagiarism: 4\n",
      "https://medium.com/simple-ai/logistic-regression-intro-to-machine-learning-7-ba18ab305b24?source=search_post\n",
      "https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-10-6ff502b2db45?source=search_post\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_links(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting class probabilities for the input data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>author_A</th>\n",
       "      <th>author_B</th>\n",
       "      <th>link_A</th>\n",
       "      <th>link_B</th>\n",
       "      <th>article_A</th>\n",
       "      <th>article_B</th>\n",
       "      <th>c_20</th>\n",
       "      <th>lcs_word</th>\n",
       "      <th>word_count_A</th>\n",
       "      <th>word_count_B</th>\n",
       "      <th>curtailment_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>196</td>\n",
       "      <td>Jahnavi Mahanta</td>\n",
       "      <td>RealityEngines.AI</td>\n",
       "      <td>https://medium.com/@mahjahnavi/natural-languag...</td>\n",
       "      <td>https://medium.com/reality-engines/natural-lan...</td>\n",
       "      <td>Natural Language Processing — An overview of k...</td>\n",
       "      <td>Natural Language Processing — An Overview of K...</td>\n",
       "      <td>0.591416</td>\n",
       "      <td>0.831041</td>\n",
       "      <td>2545</td>\n",
       "      <td>2251</td>\n",
       "      <td>0.937946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173</td>\n",
       "      <td>291</td>\n",
       "      <td>Hrishav kumar</td>\n",
       "      <td>HT</td>\n",
       "      <td>https://medium.com/@hrishavkmr/naive-bayes-in-...</td>\n",
       "      <td>https://medium.com/@hackares/naive-bayes-algor...</td>\n",
       "      <td>Naive Bayes in Machine Learning - Hrishav kuma...</td>\n",
       "      <td>Naive Bayes Algorithm - HT - MediumOpen in app...</td>\n",
       "      <td>0.278261</td>\n",
       "      <td>0.470361</td>\n",
       "      <td>776</td>\n",
       "      <td>1173</td>\n",
       "      <td>0.796893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>286</td>\n",
       "      <td>Jinde Shubham</td>\n",
       "      <td>Victor Roman</td>\n",
       "      <td>https://medium.com/coinmonks/spam-detector-usi...</td>\n",
       "      <td>https://towardsdatascience.com/naive-bayes-int...</td>\n",
       "      <td>SPAM DETECTOR USING NAIVE BAYES - Coinmonks - ...</td>\n",
       "      <td>Naive Bayes Algorithm: Intuition and Implement...</td>\n",
       "      <td>0.214646</td>\n",
       "      <td>0.519052</td>\n",
       "      <td>1181</td>\n",
       "      <td>2468</td>\n",
       "      <td>0.796728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419</td>\n",
       "      <td>456</td>\n",
       "      <td>rohan.arora</td>\n",
       "      <td>Hiromi Suenaga</td>\n",
       "      <td>https://medium.com/analytics-vidhya/traditiona...</td>\n",
       "      <td>https://medium.com/@hiromi_suenaga/machine-lea...</td>\n",
       "      <td>Naive Bayes and Logistic Regression for NLP - ...</td>\n",
       "      <td>Machine Learning 1: Lesson 10 - Hiromi Suenaga...</td>\n",
       "      <td>0.114309</td>\n",
       "      <td>0.531863</td>\n",
       "      <td>2448</td>\n",
       "      <td>12776</td>\n",
       "      <td>0.772266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>518</td>\n",
       "      <td>Akshay Chavan</td>\n",
       "      <td>Pradeepsingam</td>\n",
       "      <td>https://medium.com/@akshayc123/naive-bayes-cla...</td>\n",
       "      <td>https://medium.com/@pradeepsingam333/naive-bay...</td>\n",
       "      <td>Naive Bayes Classifier (NB) : - Akshay Chavan ...</td>\n",
       "      <td>Naive Bayes(NB) Classifier - Pradeepsingam - M...</td>\n",
       "      <td>0.214967</td>\n",
       "      <td>0.452203</td>\n",
       "      <td>1475</td>\n",
       "      <td>1342</td>\n",
       "      <td>0.771519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B         author_A           author_B  \\\n",
       "0   93  196  Jahnavi Mahanta  RealityEngines.AI   \n",
       "1  173  291    Hrishav kumar                 HT   \n",
       "2   22  286    Jinde Shubham       Victor Roman   \n",
       "3  419  456      rohan.arora     Hiromi Suenaga   \n",
       "4  312  518    Akshay Chavan      Pradeepsingam   \n",
       "\n",
       "                                              link_A  \\\n",
       "0  https://medium.com/@mahjahnavi/natural-languag...   \n",
       "1  https://medium.com/@hrishavkmr/naive-bayes-in-...   \n",
       "2  https://medium.com/coinmonks/spam-detector-usi...   \n",
       "3  https://medium.com/analytics-vidhya/traditiona...   \n",
       "4  https://medium.com/@akshayc123/naive-bayes-cla...   \n",
       "\n",
       "                                              link_B  \\\n",
       "0  https://medium.com/reality-engines/natural-lan...   \n",
       "1  https://medium.com/@hackares/naive-bayes-algor...   \n",
       "2  https://towardsdatascience.com/naive-bayes-int...   \n",
       "3  https://medium.com/@hiromi_suenaga/machine-lea...   \n",
       "4  https://medium.com/@pradeepsingam333/naive-bay...   \n",
       "\n",
       "                                           article_A  \\\n",
       "0  Natural Language Processing — An overview of k...   \n",
       "1  Naive Bayes in Machine Learning - Hrishav kuma...   \n",
       "2  SPAM DETECTOR USING NAIVE BAYES - Coinmonks - ...   \n",
       "3  Naive Bayes and Logistic Regression for NLP - ...   \n",
       "4  Naive Bayes Classifier (NB) : - Akshay Chavan ...   \n",
       "\n",
       "                                           article_B      c_20  lcs_word  \\\n",
       "0  Natural Language Processing — An Overview of K...  0.591416  0.831041   \n",
       "1  Naive Bayes Algorithm - HT - MediumOpen in app...  0.278261  0.470361   \n",
       "2  Naive Bayes Algorithm: Intuition and Implement...  0.214646  0.519052   \n",
       "3  Machine Learning 1: Lesson 10 - Hiromi Suenaga...  0.114309  0.531863   \n",
       "4  Naive Bayes(NB) Classifier - Pradeepsingam - M...  0.214967  0.452203   \n",
       "\n",
       "   word_count_A  word_count_B  curtailment_prob  \n",
       "0          2545          2251          0.937946  \n",
       "1           776          1173          0.796893  \n",
       "2          1181          2468          0.796728  \n",
       "3          2448         12776          0.772266  \n",
       "4          1475          1342          0.771519  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = predict_curtailment('naive_bayes')\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential plagiarism: 0\n",
      "https://medium.com/@mahjahnavi/natural-language-processing-an-overview-of-key-algorithms-and-their-evolution-2d9612d1f764?source=search_post\n",
      "https://medium.com/reality-engines/natural-language-processing-an-overview-of-key-algorithms-and-their-evolution-3588d2cef90f?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 1\n",
      "https://medium.com/@hrishavkmr/naive-bayes-in-machine-learning-5c0972340b76?source=search_post\n",
      "https://medium.com/@hackares/naive-bayes-algorithm-e565daa89eb7?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 2\n",
      "https://medium.com/coinmonks/spam-detector-using-naive-bayes-c22cc740e257?source=search_post\n",
      "https://towardsdatascience.com/naive-bayes-intuition-and-implementation-ac328f9c9718?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 3\n",
      "https://medium.com/analytics-vidhya/traditional-ml-nlp-definitions-tried-tested-573026693415?source=search_post\n",
      "https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-10-6ff502b2db45?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 4\n",
      "https://medium.com/@akshayc123/naive-bayes-classifier-nb-7429a1bdb2c0?source=search_post\n",
      "https://medium.com/@pradeepsingam333/naive-bayes-nb-classifier-185f2ee5d840?source=search_post\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_links(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting class probabilities for the input data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>author_A</th>\n",
       "      <th>author_B</th>\n",
       "      <th>link_A</th>\n",
       "      <th>link_B</th>\n",
       "      <th>article_A</th>\n",
       "      <th>article_B</th>\n",
       "      <th>c_20</th>\n",
       "      <th>lcs_word</th>\n",
       "      <th>word_count_A</th>\n",
       "      <th>word_count_B</th>\n",
       "      <th>curtailment_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>107</td>\n",
       "      <td>Ashutosh Dutt Mishra</td>\n",
       "      <td>Synced</td>\n",
       "      <td>https://medium.com/datadriveninvestor/ensemble...</td>\n",
       "      <td>https://medium.com/@Synced/how-random-forest-a...</td>\n",
       "      <td>Ensemble Learning and Random Forest - Data Dri...</td>\n",
       "      <td>How Random Forest Algorithm Works in Machine L...</td>\n",
       "      <td>0.069680</td>\n",
       "      <td>0.441818</td>\n",
       "      <td>550</td>\n",
       "      <td>1188</td>\n",
       "      <td>0.691771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>153</td>\n",
       "      <td>Bhartendu Dubey</td>\n",
       "      <td>Krishni</td>\n",
       "      <td>https://medium.com/@bhartendudubey/random-fore...</td>\n",
       "      <td>https://medium.com/datadriveninvestor/random-f...</td>\n",
       "      <td>Random Forest Regression - Bhartendu Dubey - M...</td>\n",
       "      <td>A Beginners Guide to Random Forest Regression ...</td>\n",
       "      <td>0.097859</td>\n",
       "      <td>0.383481</td>\n",
       "      <td>339</td>\n",
       "      <td>765</td>\n",
       "      <td>0.670580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156</td>\n",
       "      <td>258</td>\n",
       "      <td>Julia Kho</td>\n",
       "      <td>Gopal Singh</td>\n",
       "      <td>https://towardsdatascience.com/why-random-fore...</td>\n",
       "      <td>https://medium.com/data-science-bridge/random-...</td>\n",
       "      <td>Why Random Forest is My Favorite Machine Learn...</td>\n",
       "      <td>Random Forest Regression - Data Science Bridge...</td>\n",
       "      <td>0.149805</td>\n",
       "      <td>0.296332</td>\n",
       "      <td>1036</td>\n",
       "      <td>850</td>\n",
       "      <td>0.647737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>136</td>\n",
       "      <td>Terence S</td>\n",
       "      <td>Hiromi Suenaga</td>\n",
       "      <td>https://medium.com/@terenceshin/52-weeks-of-da...</td>\n",
       "      <td>https://medium.com/@hiromi_suenaga/machine-lea...</td>\n",
       "      <td>52 Weeks of Data Science: My First Machine Lea...</td>\n",
       "      <td>Machine Learning 1: Lesson 6 - Hiromi Suenaga ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419958</td>\n",
       "      <td>481</td>\n",
       "      <td>12003</td>\n",
       "      <td>0.601707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>183</td>\n",
       "      <td>Bhartendu Dubey</td>\n",
       "      <td>Hiromi Suenaga</td>\n",
       "      <td>https://medium.com/@bhartendudubey/random-fore...</td>\n",
       "      <td>https://medium.com/@hiromi_suenaga/machine-lea...</td>\n",
       "      <td>Random Forest Regression - Bhartendu Dubey - M...</td>\n",
       "      <td>Machine Learning 1: Lesson 4 - Hiromi Suenaga ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.418879</td>\n",
       "      <td>339</td>\n",
       "      <td>11456</td>\n",
       "      <td>0.600714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B              author_A        author_B  \\\n",
       "0  104  107  Ashutosh Dutt Mishra          Synced   \n",
       "1   78  153       Bhartendu Dubey         Krishni   \n",
       "2  156  258             Julia Kho     Gopal Singh   \n",
       "3   63  136             Terence S  Hiromi Suenaga   \n",
       "4   78  183       Bhartendu Dubey  Hiromi Suenaga   \n",
       "\n",
       "                                              link_A  \\\n",
       "0  https://medium.com/datadriveninvestor/ensemble...   \n",
       "1  https://medium.com/@bhartendudubey/random-fore...   \n",
       "2  https://towardsdatascience.com/why-random-fore...   \n",
       "3  https://medium.com/@terenceshin/52-weeks-of-da...   \n",
       "4  https://medium.com/@bhartendudubey/random-fore...   \n",
       "\n",
       "                                              link_B  \\\n",
       "0  https://medium.com/@Synced/how-random-forest-a...   \n",
       "1  https://medium.com/datadriveninvestor/random-f...   \n",
       "2  https://medium.com/data-science-bridge/random-...   \n",
       "3  https://medium.com/@hiromi_suenaga/machine-lea...   \n",
       "4  https://medium.com/@hiromi_suenaga/machine-lea...   \n",
       "\n",
       "                                           article_A  \\\n",
       "0  Ensemble Learning and Random Forest - Data Dri...   \n",
       "1  Random Forest Regression - Bhartendu Dubey - M...   \n",
       "2  Why Random Forest is My Favorite Machine Learn...   \n",
       "3  52 Weeks of Data Science: My First Machine Lea...   \n",
       "4  Random Forest Regression - Bhartendu Dubey - M...   \n",
       "\n",
       "                                           article_B      c_20  lcs_word  \\\n",
       "0  How Random Forest Algorithm Works in Machine L...  0.069680  0.441818   \n",
       "1  A Beginners Guide to Random Forest Regression ...  0.097859  0.383481   \n",
       "2  Random Forest Regression - Data Science Bridge...  0.149805  0.296332   \n",
       "3  Machine Learning 1: Lesson 6 - Hiromi Suenaga ...  0.000000  0.419958   \n",
       "4  Machine Learning 1: Lesson 4 - Hiromi Suenaga ...  0.000000  0.418879   \n",
       "\n",
       "   word_count_A  word_count_B  curtailment_prob  \n",
       "0           550          1188          0.691771  \n",
       "1           339           765          0.670580  \n",
       "2          1036           850          0.647737  \n",
       "3           481         12003          0.601707  \n",
       "4           339         11456          0.600714  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = predict_curtailment('random_forest')\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential plagiarism: 0\n",
      "https://medium.com/datadriveninvestor/ensemble-learning-and-random-forest-7430ebf3da7e?source=search_post\n",
      "https://medium.com/@Synced/how-random-forest-algorithm-works-in-machine-learning-3c0fe15b6674?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 1\n",
      "https://medium.com/@bhartendudubey/random-forest-regression-d751df81cc54?source=search_post\n",
      "https://medium.com/datadriveninvestor/random-forest-regression-9871bc9a25eb?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 2\n",
      "https://towardsdatascience.com/why-random-forest-is-my-favorite-machine-learning-model-b97651fa3706?source=search_post\n",
      "https://medium.com/data-science-bridge/random-forest-regression-ddfc88c92689?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 3\n",
      "https://medium.com/@terenceshin/52-weeks-of-data-science-my-first-machine-learning-algorithm-a9d3df37aa0e?source=search_post\n",
      "https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-6-14bbb8180d49?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 4\n",
      "https://medium.com/@bhartendudubey/random-forest-regression-d751df81cc54?source=search_post\n",
      "https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-4-a536f333b20d?source=search_post\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_links(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting class probabilities for the input data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>author_A</th>\n",
       "      <th>author_B</th>\n",
       "      <th>link_A</th>\n",
       "      <th>link_B</th>\n",
       "      <th>article_A</th>\n",
       "      <th>article_B</th>\n",
       "      <th>c_20</th>\n",
       "      <th>lcs_word</th>\n",
       "      <th>word_count_A</th>\n",
       "      <th>word_count_B</th>\n",
       "      <th>curtailment_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469</td>\n",
       "      <td>597</td>\n",
       "      <td>Shubham Goyal</td>\n",
       "      <td>Knoldus Inc.</td>\n",
       "      <td>https://towardsdatascience.com/boosting-perfor...</td>\n",
       "      <td>https://medium.com/@knoldus/machinex-boosting-...</td>\n",
       "      <td>Boosting performance with XGBoost - Towards Da...</td>\n",
       "      <td>MachineX: Boosting performance with XGBoost - ...</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.908903</td>\n",
       "      <td>966</td>\n",
       "      <td>960</td>\n",
       "      <td>0.961542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>354</td>\n",
       "      <td>Ahan M R</td>\n",
       "      <td>Steven Liu</td>\n",
       "      <td>https://medium.com/intel-student-ambassadors/b...</td>\n",
       "      <td>https://towardsdatascience.com/boosting-your-w...</td>\n",
       "      <td>Building Scalable Tree Boosting Methods- Tunin...</td>\n",
       "      <td>Boosting your way to the top with XGBoost 🚀 - ...</td>\n",
       "      <td>0.304183</td>\n",
       "      <td>0.472152</td>\n",
       "      <td>790</td>\n",
       "      <td>1452</td>\n",
       "      <td>0.804681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245</td>\n",
       "      <td>406</td>\n",
       "      <td>Sai Nikhilesh Kasturi</td>\n",
       "      <td>Madan Maram</td>\n",
       "      <td>https://towardsdatascience.com/lightgbm-vs-xgb...</td>\n",
       "      <td>https://medium.com/@madanmaram/xg-boost-for-be...</td>\n",
       "      <td>XGBOOST vs LightGBM: Which algorithm wins the ...</td>\n",
       "      <td>XG Boost For Begginers - Madan Maram - MediumO...</td>\n",
       "      <td>0.214356</td>\n",
       "      <td>0.374938</td>\n",
       "      <td>2003</td>\n",
       "      <td>1402</td>\n",
       "      <td>0.739413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>296</td>\n",
       "      <td>Brian Ho</td>\n",
       "      <td>Jdsmith</td>\n",
       "      <td>https://medium.com/@brian.ho_44743/churn-model...</td>\n",
       "      <td>https://medium.com/@jdsmith1906/how-i-fell-in-...</td>\n",
       "      <td>Churn Modeling using Deep Convolution Neural N...</td>\n",
       "      <td>How I Fell in Love with XGBoost Algorithm - Jd...</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.377709</td>\n",
       "      <td>323</td>\n",
       "      <td>750</td>\n",
       "      <td>0.679457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>245</td>\n",
       "      <td>Megha Singhal</td>\n",
       "      <td>Sai Nikhilesh Kasturi</td>\n",
       "      <td>https://medium.com/analytics-vidhya/xgboost-th...</td>\n",
       "      <td>https://towardsdatascience.com/lightgbm-vs-xgb...</td>\n",
       "      <td>XGBoost : “Thousand forests is in one acorn” -...</td>\n",
       "      <td>XGBOOST vs LightGBM: Which algorithm wins the ...</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.352861</td>\n",
       "      <td>734</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.662470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B               author_A               author_B  \\\n",
       "0  469  597          Shubham Goyal           Knoldus Inc.   \n",
       "1   84  354               Ahan M R             Steven Liu   \n",
       "2  245  406  Sai Nikhilesh Kasturi            Madan Maram   \n",
       "3   79  296               Brian Ho                Jdsmith   \n",
       "4  128  245          Megha Singhal  Sai Nikhilesh Kasturi   \n",
       "\n",
       "                                              link_A  \\\n",
       "0  https://towardsdatascience.com/boosting-perfor...   \n",
       "1  https://medium.com/intel-student-ambassadors/b...   \n",
       "2  https://towardsdatascience.com/lightgbm-vs-xgb...   \n",
       "3  https://medium.com/@brian.ho_44743/churn-model...   \n",
       "4  https://medium.com/analytics-vidhya/xgboost-th...   \n",
       "\n",
       "                                              link_B  \\\n",
       "0  https://medium.com/@knoldus/machinex-boosting-...   \n",
       "1  https://towardsdatascience.com/boosting-your-w...   \n",
       "2  https://medium.com/@madanmaram/xg-boost-for-be...   \n",
       "3  https://medium.com/@jdsmith1906/how-i-fell-in-...   \n",
       "4  https://towardsdatascience.com/lightgbm-vs-xgb...   \n",
       "\n",
       "                                           article_A  \\\n",
       "0  Boosting performance with XGBoost - Towards Da...   \n",
       "1  Building Scalable Tree Boosting Methods- Tunin...   \n",
       "2  XGBOOST vs LightGBM: Which algorithm wins the ...   \n",
       "3  Churn Modeling using Deep Convolution Neural N...   \n",
       "4  XGBoost : “Thousand forests is in one acorn” -...   \n",
       "\n",
       "                                           article_B      c_20  lcs_word  \\\n",
       "0  MachineX: Boosting performance with XGBoost - ...  0.782609  0.908903   \n",
       "1  Boosting your way to the top with XGBoost 🚀 - ...  0.304183  0.472152   \n",
       "2  XG Boost For Begginers - Madan Maram - MediumO...  0.214356  0.374938   \n",
       "3  How I Fell in Love with XGBoost Algorithm - Jd...  0.111842  0.377709   \n",
       "4  XGBOOST vs LightGBM: Which algorithm wins the ...  0.115942  0.352861   \n",
       "\n",
       "   word_count_A  word_count_B  curtailment_prob  \n",
       "0           966           960          0.961542  \n",
       "1           790          1452          0.804681  \n",
       "2          2003          1402          0.739413  \n",
       "3           323           750          0.679457  \n",
       "4           734          2003          0.662470  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = predict_curtailment('xgboost')\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential plagiarism: 0\n",
      "https://towardsdatascience.com/boosting-performance-with-xgboost-b4a8deadede7?source=search_post\n",
      "https://medium.com/@knoldus/machinex-boosting-performance-with-xgboost-28c9f49998a6?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 1\n",
      "https://medium.com/intel-student-ambassadors/building-scalable-tree-boosting-methods-tuning-of-parameters-2427adb8e958?source=search_post\n",
      "https://towardsdatascience.com/boosting-your-way-to-the-top-with-xgboost-556fbe6b96d3?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 2\n",
      "https://towardsdatascience.com/lightgbm-vs-xgboost-which-algorithm-win-the-race-1ff7dd4917d?source=search_post\n",
      "https://medium.com/@madanmaram/xg-boost-for-begginers-9163ee2ed96?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 3\n",
      "https://medium.com/@brian.ho_44743/churn-modeling-using-deep-convolution-neural-networks-b7b70805aa63?source=search_post\n",
      "https://medium.com/@jdsmith1906/how-i-fell-in-love-with-xgboost-algorithm-aa903d4d3a75?source=search_post\n",
      "\n",
      "\n",
      "Potential plagiarism: 4\n",
      "https://medium.com/analytics-vidhya/xgboost-thousand-forests-is-in-one-acorn-e7deefa9a64?source=search_post\n",
      "https://towardsdatascience.com/lightgbm-vs-xgboost-which-algorithm-win-the-race-1ff7dd4917d?source=search_post\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_links(feature_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
